<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.ico"> <title>Multimodal posteriors</title> <div class=franklin-content ><h1 id=multimodal_posteriors ><a href="#multimodal_posteriors" class=header-anchor >Multimodal posteriors</a></h1> <p>TODO: How to do references?</p> <p>Summary of papers from Yao et al and Wilson et al.</p> <p>Stacking paper:</p> <ul> <li><p>When do we have multimodal posteriors?</p> <ul> <li><p>What type of multimodal posteriors do we have?</p> </ul> <li><p>Why not just run multiple chains and average over them?</p> <ul> <li><p>That&#39;s essentialy what stacking does but it is important <em>how</em> you average over them</p> </ul> <li><p>What does stacking do?</p> <ul> <li><p>Why is it not equivalent to Bayesian inference?</p> <ul> <li><p>The stacking weights are computed by estimating the predictive performance on hold out data, instead of using the marginal likelihood or some other Bayesian procedure.</p> </ul> <li><p>Why does it give better predictive performance? Empirical analysis or analytic proof?</p> <ul> <li><p>The objective function is equivalent to minimising the predictive error as the number of observations <strong>and</strong> the number of posterior samples go to infinity</p> <li><p>Analytic proof on a Cauchy toy example</p> <ul> <li><p>Would be interesting to know whether these proofs generalise</p> <li><p>Raises the general question: Can we approximate the true DG, with a wrong model and non-mixing inferences?</p> <ul> <li><p>Why is stacking able to do that?</p> <li><p>Stacking is kind of like nonparametric inference because the number of clusters/modes is not specified beforehand</p> </ul> </ul> </ul> </ul> <li><p>What are the implications for neural nets?</p> <ul> <li><p>It seems that in neural networks our models are underspecified and &#40;maybe?&#41; wrong.</p> <ul> <li><p>Using gazillion of parameters would imply that we can approximate almost any distribution so technically our model is not super wrong right?</p> </ul> <li><p>Deep ensembles shouldn&#39;t average with equal weights</p> <li><p>It might not make sense to use equal weighting of the different models</p> </ul> </ul> <h2 id=when_do_we_get_multimodality ><a href="#when_do_we_get_multimodality" class=header-anchor >When do we get multimodality?</a></h2> <p>We get multimodal posteriors either because</p> <p>a. we do not have enough data b. our model is misspecified.</p> <p>In case a the multimodality will disappear with more data but b is an inherent problem.</p> <p>Formally, if our model is correct then the Bernstein-von Mises theorem tells us that with enough data the posterior will concentrate around the true parameter value. However, what happens if our model is misspecified?</p> <p>If the model is misspecified then the limiting predictive distribution is the distribution which minimises the KL between the true data generating process and our model</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>KL</mtext><mo stretchy=false >(</mo><msub><mi>p</mi><mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo stretchy=false >(</mo><mo>⋅</mo><mo stretchy=false >)</mo><mi mathvariant=normal >∣</mi><mi mathvariant=normal >∣</mi><mi>f</mi><mo stretchy=false >(</mo><mo>⋅</mo><mi mathvariant=normal >∣</mi><mi>θ</mi><mo stretchy=false >)</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex"> \text{KL}(p_{true}(\cdot) || f(\cdot | \theta)) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class=mord >KL</span></span><span class=mopen >(</span><span class=mord ><span class="mord mathdefault">p</span><span class=msupsub ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mord mathdefault mtight" style="margin-right:0.02778em;">r</span><span class="mord mathdefault mtight">u</span><span class="mord mathdefault mtight">e</span></span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.15em;"><span></span></span></span></span></span></span><span class=mopen >(</span><span class=mord >⋅</span><span class=mclose >)</span><span class=mord >∣</span><span class=mord >∣</span><span class="mord mathdefault" style="margin-right:0.10764em;">f</span><span class=mopen >(</span><span class=mord >⋅</span><span class=mord >∣</span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class=mclose >)</span><span class=mclose >)</span></span></span></span></span> <p>Unfortunately, this reduces to a point estimate with more data. However, the key point about Bayesian inference is that we want to quantify the uncertainty in our inferences with probability so a point estimate defeats the purpose&#33;</p> <p>Instead we want a probability distribution on <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>θ</mi></mrow><annotation encoding="application/x-tex">\theta</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span></span></span></span> which minimises the predictive loss according to some divergence.</p> <h2 id=some_examples ><a href="#some_examples" class=header-anchor >Some examples</a></h2> <p>Potentially list the four examples using Turing models. For each of the four examples we have:</p> <ul> <li><p>A Turing model for the <strong>true DG</strong></p> <li><p>A Turing model for the <strong>user-defined model</strong></p> <li><p>A number of samples <strong>N</strong></p> <li><p>&#40;An <strong>analytic posterior</strong>&#41;</p> </ul> <p>Do the examples include an example where the joint posterior is exactly symmetric? If not point that out and point to Betancourt case study to show how to handle those cases.</p> <h2 id=stacking_for_multimodal_posteriors ><a href="#stacking_for_multimodal_posteriors" class=header-anchor >Stacking for Multimodal Posteriors</a></h2> <ol> <li><p>Run MCMC for multiple Chains</p> <li><p>&#40;Optional:&#41; Detect clusters in chains</p> <li><p>Determine stacking weights by optimising the weights according to predictive performance weights</p> <li><p>Check convergence. We might have missed some modes. Ideally, we would check by monitoring performance on some hold-out dataset.</p> </ol> <h2 id=key_takeaways ><a href="#key_takeaways" class=header-anchor >Key takeaways</a></h2> <ul> <li><p>Multimodality is often a sign that we need to improve our model</p> <li><p>Either we have too little data which might be fine</p> <li><p>Or our model is misspecified and we need to expand it</p> <li><p>Part 2: What about neural nets?</p> </ul> <h2 id=conclusions ><a href="#conclusions" class=header-anchor >Conclusions</a></h2> <p>Authors recommend stacking should be used in the model exploration phase because it allows to run shorter chains and diagnose potential issues with the model.</p> <p>Running multiple chains in parallel is &#40;almost&#41; free on modern hardware so this stacking approach is a promising avenue to quickly diagnose misspecified models and further use it in prediction task when we assume that our model is misspecified.</p> <p>This should be able to be used in cases when model is underspecified. However, in that case we should be able to know beforehand that our model is underspecified.</p> <p>Open research question:</p> <ul> <li><p>How do we make sure different chains explore a <em>diverse set of solutions</em>?</p> </ul> <p>If the Bayes posterior is suboptimal for prediction under model misspecification does that mean Bayes is useless? Not necessarily. Instead multimodality and bad predictions could show us that our model needs to be expanded/improved. The solution then might not lie in finding a better inference/learning algorithm but instead find a principled way to expand our models.</p> <div class=page-foot > <div class=copyright > &copy; Tim Reichelt. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>. </div> </div> </div>