<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/basic.css"> <link rel=icon  href="/assets/favicon.ico"> <title>Multimodal posteriors Part 2</title> <div class=franklin-content ><h1 id=multimodality_part_2_deep_learning ><a href="#multimodality_part_2_deep_learning">Multimodality Part 2: Deep Learning</a></h1> <ul> <li><p>Are neural networks misspecified? Wilson et al. argue yes but I am not so sure. If you have millions of parameters then your model space is either extremely large or there are some redundancies in your parameters. Both could be true.</p> <li><p>Yuling Yao: Neural networks have such a terrible posterior geometry that it is incredibly difficult to get an accurate representation of the posterior. Therefore any claim that the Bayesian posterior in neural networks is suboptimal for prediction must be carefully evaluated because it might just be a failure of the inference algorithm.</p> </ul> <p>Main argument: The main distinguishing feature of being Bayesian is marginalisation i.e. considering multiple possible parameter settings in the predictive distribution. Taking this view Bayesianism is extremely helpful for deeply learning because these models are inherently misspecified and there exist very different sets of parameters which provide similar predictive performance. Ergo people should average over different parameters when making predictions. Simply using a point estimate is not enough.</p> <p>The following challenges are identified:</p> <ul> <li><p>Finding a diverse set of parameters which give rise to functionally different predictions but with similar predictive performance</p> <ul> <li><p>This has connections to deep ensembles and bayesian model averaging</p> </ul> <li><p>We still need to give sensible priors for our architectures to make sure that our posterior isn&#39;t diffuse this means we need the right <em>inductive biases</em>.</p> <ul> <li><p>Empirical results suggest the <strong>NN architecture</strong> is a good place to work on building better priors &#40;i.e. build in invariance&#41;; the priors on the weights does not matter that much in comparison</p> </ul> </ul> <h2 id=open_questions ><a href="#open_questions">Open questions</a></h2> <ul> <li><p>Neural network architectures are usually discovered and built on a trial and error basis. Could we develop a principled workflow akin to Betancourt or Gelman et al which brings more rigour into neural network design?</p> <li><p>How can we do prior predictive checks for NNs? NN predictions from the prior will usually be nonsensical anyway.</p> <ul> <li><p>Maybe we can reuse posteriors from off-the-shelf architectures?</p> <li><p>How could we properly transfer priors between different architectures?</p> </ul> <li><p>As a long-term goal we want to use NN predictions as part of a bigger Bayesian model. For example, we might have some tabular data about the economic performance of a country and at the same time also a NN model that counts the number of cars parked in front of supermarkets from satellite images. Now we want to use the quantity of estimated cars and we want to account for uncertainty. Ideally, we only specify the &quot;forward&quot; model once in some Julia, Python code and the separately we can specify how to fit the individual components. This would heavily rely on the programmable inference ideas from Gen</p> </ul> <!-- <div class=page-foot > <div class=copyright > &copy; {{ fill author }}. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a>. </div> </div> --></div>